{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMhARnJKYOB0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install -U mlxtend\n",
    "! pip install -U statsmodels\n",
    "! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eI-xcBTqYOB6"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "from tqdm.auto import tqdm\n",
    "# Load the Boston housing dataset\n",
    "boston=datasets.load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_YbBCVPYOB9"
   },
   "source": [
    "# Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoeYq5x5YOB-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RG1YXdeYOCE"
   },
   "outputs": [],
   "source": [
    "boston_data = pd.DataFrame(boston.data)\n",
    "boston_data.columns = boston['feature_names']\n",
    "boston_data['MEDV'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlB4P6dVYOCH"
   },
   "outputs": [],
   "source": [
    "boston_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dk_kdMXUYOCL"
   },
   "outputs": [],
   "source": [
    "boston_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDlTYkTUYOCO"
   },
   "source": [
    "Run a full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-IaOR5RYOCP"
   },
   "outputs": [],
   "source": [
    "y = boston_data[\"MEDV\"]\n",
    "X = boston_data.drop([\"MEDV\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hOZEN05YOCT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = sm.add_constant(X) # by default statsmodels does not add an intercept\n",
    "# add a constant is the same as adding a column of 1 to X .\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlZ14FklYOCX"
   },
   "source": [
    "It might be easier to use R-style formulas when there are only a few variables. You do not need to explicitly add an intercept term as in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMnCxBWgYOCY",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_2 = smf.ols(formula='MEDV ~ CRIM + ZN', data=boston_data)\n",
    "res = model_2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHblXDxAYOCb"
   },
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbax6WOFYOCc"
   },
   "source": [
    "Boostrap is a key tool in modern statistics to quantify the uncertainty of estimation. It is is a computer-intensive procedure that substitutes fast computation for theoretical math. The idea is quite simple.  \n",
    "\n",
    "1. Suppose you have a dataset (sample) and use it to find $\\hat{\\theta}$, your estimate the unknown parameter $\\theta$. \n",
    "2. Then draw a new random sample of size n, with replacement, from the orignial dataset. The sample size n is the same as the size of the original dataset (sample). \n",
    "3. This new sample is called a bootstrap sample. For this bootstrap sample, we can calculate a new estimate $\\hat{\\theta}_1$. \n",
    "4. Repeat step 2 and step 3 $K$ times and get $\\hat{\\theta}_1$, $\\hat{\\theta}_2$,...,$\\hat{\\theta}_K$.\n",
    "5. The spread in these estimates tells us how large the estimation error is. Suppose we want to set a 95% confidence interval on $\\theta$, the true parameter value. And suppose we take K = 5000 bootstrap samples. The bootstrap theory suggests that approximately 95% of the time, the true parameter value falls between the 2.5th percentile of the bootstrap samples (or the 125 smallest out of 5000) and the 97.5th percentile (or the 125 largest). As such, the 2.5th percentile of $\\hat{\\theta}_1$, $\\hat{\\theta}_2$,...,$\\hat{\\theta}_{5000}$ and the 97.5th percentile provides the 95% CI for $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4dU0AJfYOCc"
   },
   "outputs": [],
   "source": [
    "bootstrapped_ests = []\n",
    "for i in tqdm(range(1000)):\n",
    "    boston_data_boot = boston_data.sample(n=len(boston_data), replace=True)\n",
    "    boston_model_boot = smf.ols(formula='MEDV ~ CRIM + ZN', data=boston_data_boot).fit()\n",
    "    bootstrapped_ests.append(boston_model_boot.params[['CRIM', 'ZN']])\n",
    "\n",
    "b_CRIMs, b_ZNs = zip(*bootstrapped_ests)\n",
    "\n",
    "print(\"The 95% bootstrapped CI of b_CRIMs is [{:.2f}, {:.2f}].\".format(\n",
    "    np.percentile(b_CRIMs, 2.5),\n",
    "    np.percentile(b_CRIMs, 97.5)))\n",
    "\n",
    "print(\"The 95% bootstrapped CI of b_ZNs is [{:.2f}, {:.2f}].\".format(\n",
    "    np.percentile(b_ZNs, 2.5),\n",
    "    np.percentile(b_ZNs, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gwi3HSRHYOCf"
   },
   "source": [
    "# Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0g5vt4BJYOCf"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Iw2QXFEYOCi"
   },
   "source": [
    "## sklearn model without selection  \n",
    "[Read the manual](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qA8zHYoWYOCj"
   },
   "outputs": [],
   "source": [
    "model_3 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGGDRTRLYOCn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YE-JyPtvYOCs",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_3.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Pd5EhD9YOCv"
   },
   "source": [
    "## Stepwise Regression using sklearn + mlxtend.  \n",
    "[Read the manual and examples](http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGKFE2xaYOCw"
   },
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "model_sfs = SFS(model_3, scoring='neg_mean_squared_error', k_features=4, verbose=1, cv=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PvB-4OSYOCy"
   },
   "outputs": [],
   "source": [
    "model_sfs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmI66FqYYOC2"
   },
   "outputs": [],
   "source": [
    "model_sfs.get_metric_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TReqZ8XFYOC5"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(model_sfs.get_metric_dict()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRnI1zOiYOC8"
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig1 = plot_sfs(model_sfs.get_metric_dict(), kind='std_dev')\n",
    "plt.title('Sequential Forward Selection')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvM-CJkbYOC-"
   },
   "source": [
    "After selection, we need to refit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxEQk4rGYOC_"
   },
   "outputs": [],
   "source": [
    "X_selected = model_sfs.transform(X)\n",
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9MW71YKYODB"
   },
   "outputs": [],
   "source": [
    "model_3_after_selection = model_3.fit(X_selected, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOcr8H3HYODD"
   },
   "source": [
    "We can use the refitted model to make predictions (in-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cVpBscFYODD"
   },
   "outputs": [],
   "source": [
    "model_3_after_selection.predict(X_selected)[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UuD9X_YYODH"
   },
   "source": [
    "## Recursive feature elimination with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "casSCMuSYODH"
   },
   "source": [
    "[Manual](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8U16HF4KYODI"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OW_N8iyGYODL"
   },
   "outputs": [],
   "source": [
    "model_RFE = RFE(model_3, n_features_to_select=4)\n",
    "model_RFE.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2sTPDKjYODO"
   },
   "outputs": [],
   "source": [
    "model_RFE.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KF1Kt3rYODR"
   },
   "source": [
    "Get the selected X variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "343-jkHkYODS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.loc[:, model_RFE.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ML4DFRmTYODU"
   },
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMus-hP9YODU"
   },
   "source": [
    "[Lasso Manual](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)  \n",
    "[LassoCV Manual](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SccMKFcCYODV"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV, lars_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ijl_FFHYODX"
   },
   "source": [
    "We can set the alpha ($\\lambda$ in slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNKIePO6YODX"
   },
   "outputs": [],
   "source": [
    "model_lasso = Lasso(alpha = 0.1, normalize=True)\n",
    "model_lasso.fit(X, y)\n",
    "model_lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZewviUWYODa"
   },
   "source": [
    "Which variables are selected? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbUIDQMvYODb"
   },
   "outputs": [],
   "source": [
    "X.columns[np.abs(model_lasso.coef_) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYIcd1T2YODc"
   },
   "source": [
    "LassoCV can search for best alpha automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_55zkbdeYODd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_lassoCV = LassoCV(cv=5, normalize=True)\n",
    "model_lassoCV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiuE7se6YODf"
   },
   "outputs": [],
   "source": [
    "model_lassoCV.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2V09xUuYODh"
   },
   "source": [
    "We can also visualize the Lasso Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3-pu1aqYODi"
   },
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36Vv4QnlYODk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alphas_lasso, coefs_lasso, _ = model_lasso.path(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSGV1U7yYODm",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, _, coefs = lars_path(X.values, y.values.flatten(), method='lasso')\n",
    "\n",
    "xx = np.sum(np.abs(coefs.T), axis=1)\n",
    "xx /= xx[-1]\n",
    "plt.plot(xx, coefs.T)\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.vlines(xx, ymin, ymax, linestyle='dashed')\n",
    "plt.xlabel('|coef| / max|coef|')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('LASSO Path')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8o3Spg7YODo"
   },
   "source": [
    "# Train-test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWagkbBMYODo"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMiyRn_MYODq"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADylII41YODu"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdlwBuWtYOD0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qK0RpQeuYOD3"
   },
   "source": [
    "**Important**: Standardizing/Normalizing data is part of the model training process. You shoud fit a standardizer (learning the mean and std from the train set) and use it to transform both the train and test set. See [here](https://scikit-learn.org/stable/modules/preprocessing.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_0w653UYOD4"
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3w8Qcmm_YOD6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_lassoCV = LassoCV(cv=5, normalize=False) # note we don't need to normalize again\n",
    "model_lassoCV.fit(scaler.transform(X_train), y_train) # note we transform X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqL-4k4LYOEA"
   },
   "source": [
    "Predict test set and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSRpVLkPYOEA"
   },
   "outputs": [],
   "source": [
    "y_hat_test = model_lassoCV.predict(scaler.transform((X_test))) \n",
    "# note we transform X_test using the scaler learned from the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clSBD456YOED"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omB6lsrsYOEG",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(y_true=y_test, y_pred=y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBEwNZw3HCZa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1yvnKMWtncLtKSvle7rb_v_UC3w3nbVJy",
     "timestamp": 1667254304459
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
