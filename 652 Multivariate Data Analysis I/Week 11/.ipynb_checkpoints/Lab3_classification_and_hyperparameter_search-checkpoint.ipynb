{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIkO5R-ba2p_"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xfwizz_jvIFb"
   },
   "outputs": [],
   "source": [
    "# set terminal options to display all outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eL6zKLoQlH5E"
   },
   "outputs": [],
   "source": [
    "!pip install -U xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8Z0vKlUlJoy"
   },
   "outputs": [],
   "source": [
    "!pip install -U pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwJrurcOvIFf"
   },
   "source": [
    "## 1. Dataset\n",
    "- We are using \"default of credit card clients Data Set\" from UCI Machine Learning Repository\n",
    "- This dataset consists of customers' default payments (fail to pay the credit card by the due date) data in Taiwan among six data mining methods\n",
    "- Binary dependent variable \"default payment next month\" (1 = default, 0 = not default)\n",
    "- Detailed attributes descriptions [here](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nnk2BOGVvIFf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "df = pd.read_excel('http://fengmai.net//download/courses/2020S-BIA652NT-Pub/Week10-Classification%20and%20Hyperparameter%20Search%20using%20Python/default%20of%20credit%20card%20clients.xls', header = 1).drop('ID', axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tU73mKJQvIFj"
   },
   "outputs": [],
   "source": [
    "# basic data exploration\n",
    "df.shape\n",
    "df.columns\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_9wJHT1xmKF"
   },
   "outputs": [],
   "source": [
    "df.describe().T.to_excel(\"desc_stats.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GTO2yh2vIFm"
   },
   "outputs": [],
   "source": [
    "df['default payment next month'].value_counts()\n",
    "# note that this is an imbalanced dataset, we should look at the confusion matrix rather than overall accuracy (will be discussed later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBrp4dvbvIFo"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style = 'whitegrid')\n",
    "sns.countplot(data = df, x = 'default payment next month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qItdpeCCvIFs"
   },
   "source": [
    "## 2. Creating Dummy Variables (One-Hot Encoding)\n",
    "- Many machine learning algorithms cannot work with categorical data directly. Thus, categorical data must be converted to numbers (dummy variables), e.g., \"cold\": 1, \"warm\": 2, \"hot\": 3\n",
    "- Yet, there may still be problems when there is no ordinal relationship and allowing the representation to lean on any such relationship might be damaging to learning to solve the problem, e.g. \"dog\": 1, \"cat\": 2. In these cases, we would like to give the model more expressive power to learn a probability-like number for each possible label value\n",
    "- One Hot Encoding: a representation of categorical variables as binary vectors\n",
    "    - first requires that the categorical values be mapped to integer values\n",
    "    - each integer value is represented as a binary vector that is all zero values except the index of the integer, which is marked with a 1\n",
    "- More details [here](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fv_EeA2cvIFt"
   },
   "outputs": [],
   "source": [
    "df.apply(lambda col: len(col.unique()))\n",
    "# in our case, ['SEX', 'EDUCATION', 'MARRIAGE'] are dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-CX2i5ZvIFv"
   },
   "outputs": [],
   "source": [
    "col = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "df2 = pd.get_dummies(df, columns = col, drop_first=True)\n",
    "df2.head()\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NNlFGMJvIFy"
   },
   "source": [
    "## 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8HzMUOrbEJC"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "logit_mod = sm.Logit(df2['default payment next month'], sm.add_constant((df2.drop('default payment next month', axis = 1))))\n",
    "logit_res = logit_mod.fit()\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTuvqLSwcEtk"
   },
   "outputs": [],
   "source": [
    "to_drop = []\n",
    "corr_matrix = sm.add_constant((df2.drop('default payment next month', axis = 1))).corr()\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if (corr_matrix.iloc[i, j] >= 0.80) and i != j:\n",
    "            print(f\"{corr_matrix.columns[i]} and {corr_matrix.index[j]} have a correlation of {corr_matrix.iloc[i, j]}\" ) \n",
    "            to_drop.append(corr_matrix.index[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbS2rf9Icezx"
   },
   "outputs": [],
   "source": [
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZVwhV9Avjlh_"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "logit_mod = sm.Logit(df2['default payment next month'], sm.add_constant((df2.drop(['default payment next month'] + to_drop, axis = 1))))\n",
    "logit_res = logit_mod.fit(maxiter = 1000)\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_EBDl6F2SME"
   },
   "outputs": [],
   "source": [
    "log_sum = logit_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyeY8h8k5Jvq"
   },
   "outputs": [],
   "source": [
    "log_sum.as_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccvpEfcOvIFz"
   },
   "source": [
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)  \n",
    "\n",
    "**Make sure that you choose the regularization hyperparameter (C) wisely! The default C is 1.0, which can be very detrimental to model performance. Note that C is the inverse of lambda, smaller C means stronger penalty for complicated models. ** In this example, we set C to a large number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qaGnWn33vIFz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y = df2['default payment next month']\n",
    "x = df2.drop('default payment next month', axis = 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIKtUr-va2qG"
   },
   "outputs": [],
   "source": [
    "# standardization before fitting data so that they have 0-mean and unit-variance: z = (x - u) / s\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_s = scaler.transform(x_train)\n",
    "x_test_s = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5QgzWqta2qG"
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression(C=100, solver = 'lbfgs', max_iter = 1000)\n",
    "lg.fit(x_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "moepbu_la2qH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_predict_test = lg.predict(x_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCJhirOka2qH"
   },
   "outputs": [],
   "source": [
    "y_predict_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sibaXCdOa2qH"
   },
   "outputs": [],
   "source": [
    "y_test[:20].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0qeBOrGvIF2"
   },
   "source": [
    "## 4. Performance evaluation\n",
    "- Accuracy\n",
    "- Confusion Matrix\n",
    "- Precision, Recall, and F1-score\n",
    "- More details [here](https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffdJxXflvIF2"
   },
   "source": [
    "### 4.1. Accuracy\n",
    "- Accuracy is often used to measure model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZlsZnH1a2qI"
   },
   "outputs": [],
   "source": [
    "lg.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-18QG_mvIF3"
   },
   "outputs": [],
   "source": [
    "print('classifier accuracy is {:.2f}'.format(lg.score(x_test_s, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SV-eF6Iia2qI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('classifier accuracy is {:.2f}'.format(accuracy_score(y_true=y_test, y_pred=y_predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kTpDqcra2qI"
   },
   "source": [
    "- However, for an imbalanced classification problem where **the sample is imbalanced (one category represents the overwhelming majority of the data points)** or **the cost is asymmetric**, accuracy can be a problematic metric\n",
    "  - prediction of rare diseases\n",
    "  - mortgage default\n",
    "  - antibody test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TojZshGmvIF5"
   },
   "source": [
    "### 4.2. Confusion Matrix\n",
    "- Two types of prediction errors:\n",
    "  - False Positive: Predict an event when there was no event\n",
    "  - False Negative: Predict no event when in fact there was an event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iv4_LbXMvIF5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_predict_test)\n",
    "print('confusion matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kn3Uv4rla2qJ"
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f'tn: {tn}, fp: {fp}, fn: {fn}, tp: {tp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLIyl8n6vIF9"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(pd.DataFrame(cm), annot = True, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0v0JpltrvIGA"
   },
   "source": [
    "### 4.3. Precision, Recall, and F1-score\n",
    "- Precision: precentage of true cases among the predicated true cases\n",
    "- Recall:  precentage of true cases that have been retrieved over the total number of true cases\n",
    "    - Metrics: <br>\n",
    "   $$ \n",
    "    \\begin{align}\n",
    "     precision~of~positive~class &= \\frac{true~positives}{ true~positives + false~positives} \\\\\n",
    "     recall~of~positive~class &= \\frac{true~positives}{ true~positives + false~negatives}\n",
    "    \\end{align}\n",
    "    $$\n",
    "- F-score: $$\\frac{2*precision*recall}{precision+recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7xtdfZtvIGB"
   },
   "outputs": [],
   "source": [
    "# classification report\n",
    "print('classification report:\\n', classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flT3iVLovIGH"
   },
   "source": [
    "### 4.4 Decision threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEX-661fvIGI"
   },
   "source": [
    "By default, most classification algorithms can output a predicted probability using `predict_proba()`. The default decision threshold is $p = 0.5$, meaning if $p(y|x) > 0.5$ then predicted class is 1. Sometimes it is necassary to use a difference decision threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kvq_rHhFvIGI"
   },
   "outputs": [],
   "source": [
    "predict_prob = lg.predict_proba(x_test_s)\n",
    "# note that the predicted prob has 2 columns and they add up to 1. \n",
    "# The columns give the predicted probability of each class.\n",
    "predict_prob[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rFo2cTbvIGK"
   },
   "source": [
    "When we set the threshold to 0.1, the recall for y = 1 class goes up, and precision goes down (think about why). This is a fundamental tradeoff that you need to make. The optimal threshold depends on \n",
    "- the relative cost between false positive and false negative. \n",
    "- how unbalanced the classes are in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mXvIH5ivIGL",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('classification report:\\n', classification_report(y_test, predict_prob[:,1] > 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQs82MS0vIGO"
   },
   "source": [
    "## 5. ROC curve and Precision-Recall Curve\n",
    "- ROC curve and AUC\n",
    "- Precision-Recall Curve\n",
    "- More details [here](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5a0uMXyvIGP"
   },
   "source": [
    "### 5.1 ROC curve and AUC\n",
    "- **Receiver operating characteristic (ROC) curve** plots the true positive rate (TPR) vs the false positive rate (FPR) as a function of the modelâ€™s threshold for classifying positives\n",
    "- Metrics: <br>\n",
    "\n",
    "$$ \n",
    "    \\begin{align}\n",
    "     true~positive~rate~(tpr) &= recall~of~positive~class  \\\\\n",
    "     false~positive~rate~(fpr) &= \\frac{false~positives}{ false~positives + true~negatives} \\\\\n",
    "     & = 1- recall~of~negative~class\n",
    "    \\end{align}\n",
    "$$ \n",
    "\n",
    "- **Area under the curve (AUC)** is a metric to calculate the overall performance of a classification model based on area under the ROC curve \n",
    "- **Important**: To genenrate the ROC curve, you need to use the output from `predict_proba`, not `predict`! The `roc_curve` function automatically varies the decision threshold and computes the TP and FP at any given threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bR1EyC0vIGP"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEd8EHXcvIGU"
   },
   "outputs": [],
   "source": [
    "predict_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXu7zzp2vIGX"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predict_prob[:, 1])\n",
    "print('AUC: {:.2f}'.format(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYHv1VefvIGZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (7, 5))\n",
    "plt.plot(fpr, tpr, color = 'darkorange', lw = 2, label = 'Logistic Reg')\n",
    "plt.plot([0, 1], [0, 1], color = 'navy', lw = 2, linestyle = '--', label = 'Random Guess')\n",
    "plt.title('AUC of Logistic Model')\n",
    "plt.xlabel('False Positive Rate (1-Specificity)')\n",
    "plt.ylabel('True Positive Rate (Recall)' )\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iN3usZ6a2qN"
   },
   "outputs": [],
   "source": [
    "# !!!! Warning! Wrong Approach !!!! #######\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predict_prob[:, 1] > 0.5)\n",
    "print('AUC: {:.2f}'.format(auc(fpr, tpr)))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (7, 5))\n",
    "plt.plot(fpr, tpr, color = 'darkorange', lw = 2, label = 'Logistic Reg')\n",
    "plt.plot([0, 1], [0, 1], color = 'navy', lw = 2, linestyle = '--', label = 'Random Guess')\n",
    "plt.title('AUC of Logistic Model (Wrong Way)')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WO_t1voza2qN"
   },
   "source": [
    "Using the binary classification output instead of predicted probability to construct the ROC curve and to compute AUC is a common mistake. See [SAS's Python API tutorial](https://github.com/sassoftware/saspy-examples/blob/8b5caae91b375276c3d20b2aa62a3fce9ff881f7/SAS_contrib/SASPy%20for%20Machine%20Learning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2W_VgfZevIGb"
   },
   "source": [
    "### 5.2 Precision-Recall Curve\n",
    "- **Precision-Recall Curve** plots the precision (y-axis) and the recall (x-axis) for different thresholds, much like the ROC curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaduEb4JvIGc"
   },
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, predict_prob[:,1] )\n",
    "\n",
    "plt.figure(figsize = (7, 5))\n",
    "plt.plot(recall, precision, color='darkorange', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision_Recall_Curve of Logistic Model')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHF-4sBGa2qO"
   },
   "source": [
    "Quiz: When decision threshold increases, what happens to the horizontal axis (recall)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qabYWth8vIGf"
   },
   "source": [
    "## 6. PCA\n",
    "- **Principal Component Analysis (PCA)** is a dimension-reduction tool that can be used to reduce a large set of variables to a small set that still contains most of the information in the large set.\n",
    "- The main purpose of principal component analysis is to:\n",
    "    - identify hidden pattern in a data set,\n",
    "    - reduce the dimensionnality of the data by removing the noise and redundancy in the data,\n",
    "    - deal with multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pG709HCPvIGf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# correlation matrix\n",
    "corr = df2.iloc[:, :14].corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUnbwku1vIGh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "y = df2['default payment next month'].values.astype(float)\n",
    "x = df2.drop('default payment next month', axis = 1).values.astype(float)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Note that standardization is important in PCA since the latter projects your original data onto directions which maximize the variance\n",
    "# If the features have different scales, this projection may get skrewed\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_s = scaler.transform(x_train)\n",
    "x_test_s = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNOxQcaJa2qO"
   },
   "outputs": [],
   "source": [
    "# find the number of principle components which have 80% information of the original dataset\n",
    "pca = PCA(n_components = 0.8)\n",
    "pca.fit(x_train_s)\n",
    "print('Variance ratio of each pc:\\n', pca.explained_variance_ratio_, '\\n')\n",
    "print('Explained variance of each pc:\\n', pca.explained_variance_, '\\n')\n",
    "print('Selected {} pcs'.format(pca.n_components_))\n",
    "print('Original dataset shape: ', df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAp3xe1HvIGj"
   },
   "outputs": [],
   "source": [
    "x_train_pca = pca.transform(x_train_s)\n",
    "x_test_pca = pca.transform(x_test_s)\n",
    "\n",
    "lg = LogisticRegression(C = 1000, solver = 'lbfgs', max_iter = 1000)\n",
    "lg.fit(x_train_pca, y_train)\n",
    "\n",
    "predict = lg.predict(x_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Mfw8zLYvIGn"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print('classifier accuracy is {:.2f}'.format(lg.score(x_test_pca, y_test)))\n",
    "\n",
    "cm = confusion_matrix(y_test, predict)\n",
    "print('confusion matrix:\\n', cm)\n",
    "\n",
    "print('classification report:\\n', classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOzNDnQxcez1"
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda_mod = LinearDiscriminantAnalysis()\n",
    "lda_mod.fit(x_train_pca, y_train)\n",
    "predict = lda_mod.predict(x_test_pca)\n",
    "cm = confusion_matrix(y_test, predict)\n",
    "print('confusion matrix:\\n', cm)\n",
    "print('classification report:\\n', classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkF2lckkcez1"
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda_mod = QuadraticDiscriminantAnalysis()\n",
    "qda_mod.fit(x_train_pca, y_train)\n",
    "predict = qda_mod.predict(x_test_pca)\n",
    "cm = confusion_matrix(y_test, predict)\n",
    "print('confusion matrix:\\n', cm)\n",
    "print('classification report:\\n', classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4hdv_W8cez1"
   },
   "outputs": [],
   "source": [
    "qda_mod = QuadraticDiscriminantAnalysis()\n",
    "qda_mod.fit(x_train_pca, y_train)\n",
    "predict = qda_mod.predict_proba(x_test_pca)[:, 1] > 0.9\n",
    "cm = confusion_matrix(y_test, predict)\n",
    "print('confusion matrix:\\n', cm)\n",
    "print('classification report:\\n', classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDBkVGA1a2qP"
   },
   "source": [
    "## Deciding the number of principal components by cross validation\n",
    "- We can use CV on train set to decide the best number of PC (2-20) to maximize AUC\n",
    "- Steps:\n",
    "    - build a pipeline which executes necessary steps in a row\n",
    "    - set the range of parameters to be tuned\n",
    "    - grid search using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3fad79Ta2qP"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# build a pipeline which executes three steps in a row\n",
    "pipe = Pipeline([\n",
    "    ('standardization', preprocessing.StandardScaler()),\n",
    "    ('pca', PCA()),    \n",
    "    ('lg', LogisticRegression(C=0.01, solver = 'lbfgs', max_iter = 1000))\n",
    "])\n",
    "\n",
    "# set the range of parameters to be tuned\n",
    "param_grid = {'pca__n_components':  range(2, 21)}\n",
    "# grid search using cross validation\n",
    "grid = GridSearchCV(pipe, cv = 3, param_grid = param_grid, scoring = 'roc_auc', refit=True, verbose=1)\n",
    "grid_fit = grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9Y-ilsya2qQ"
   },
   "source": [
    "We can use the following function to help report the results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7plmJsCda2qQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            \n",
    "report(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdVKlXRya2qQ"
   },
   "source": [
    "Once the grid search is complete, the `GridSearchCV` will automatically refit on the entire train set. You can use the object to predict new observations directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYMsShqUa2qQ"
   },
   "outputs": [],
   "source": [
    "# This is not needed, unless you set refit = False when creating GridSearchCV. \n",
    "# final_model = grid.best_estimator_.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZDv4i_1a2qQ"
   },
   "outputs": [],
   "source": [
    "grid.predict_proba(x_test)[:3]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "x0qeBOrGvIF2",
    "ffdJxXflvIF2",
    "TojZshGmvIF5",
    "0v0JpltrvIGA",
    "flT3iVLovIGH",
    "eQs82MS0vIGO",
    "D5a0uMXyvIGP",
    "2W_VgfZevIGb",
    "qabYWth8vIGf",
    "mDBkVGA1a2qP"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
