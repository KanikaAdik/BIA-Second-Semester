{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBSToOomn9hO"
   },
   "outputs": [],
   "source": [
    " ! pip install pymc3\n",
    " #! conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6l5CxKBpW3o9"
   },
   "outputs": [],
   "source": [
    "!pip install -U pymc3[plots] -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T21:22:32.679396Z",
     "start_time": "2017-08-23T21:22:32.007586Z"
    },
    "id": "ZFMYwrEGn9hO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pymc3 as pm\n",
    "import numpy.random as npr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFVNRgP9n9hO"
   },
   "source": [
    "# Bayesian Inference with PyMC3\n",
    "\n",
    "The notebook borrows examples from the following sources: \n",
    "- [**ericmjl**.github.io/**bayesian-stats-talk**](https://ericmjl.github.io/bayesian-stats-talk)\n",
    "- PyMC3 tutorials https://docs.pymc.io/nb_tutorials/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucTl-njEn9hO"
   },
   "source": [
    "## Bayesian inference in one equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRrgqZVKn9hO"
   },
   "source": [
    "$$ P(\\theta|D) = \\frac{P(D|\\theta)P(\\theta)}{P(D)} $$\n",
    "\n",
    "- $ P(D|\\theta) $: Probability of the data arising given the parameters (Likelihood).\n",
    "- $ P(\\theta|D) $: Distribution of the parameters given the data (Posterior).\n",
    "- $ P(\\theta) $: Prior belief about the parameter (Prior).\n",
    "- $ P(D) $: Probability of the data arising, globally (Difficult to compute)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iLgJIPrn9hO"
   },
   "source": [
    "## Practical reasons for bayesian inference\n",
    "\n",
    "- can incorporate prior knowledge and belief   \n",
    "- can update models after new data becomes available  \n",
    "- provide a way to fit complicated models  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QUgbpAon9hO"
   },
   "source": [
    "## `pymc3`\n",
    "\n",
    "- Some simple Bayesian models can be computed by hand. See readings: _The Conjugate Prior for the Normal Distribution_.\n",
    "- Most Bayesian models are difficult to solve because of **complicated integrals** needed to compute **posterior distributions** (the $P(D)$ part).\n",
    "- **M**arkov **C**hain **M**onte **C**arlo (MCMC) sampling enables us to **estimate shape of posterior distributions** using simulation; calculus not required. See readings: _MCMC sampling for dummies_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qbX4JEfn9hP"
   },
   "source": [
    "\n",
    "![](https://github.com/pymc-devs/pymc3/blob/master/docs/pymc3_logo.jpg?raw=true)\n",
    "\n",
    "- Library of **statistical distributions**, **sampling algorithms**, and **syntax** for specifying statistical models\n",
    "- Everything in Python!\n",
    "- Alternatives are [stan](https://mc-stan.org/), [Edward](http://edwardlib.org), and [PyRo](https://pyro.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0k3KUepfn9hP"
   },
   "source": [
    "## parameter estimation\n",
    "\n",
    "Frequetist: \"is the true value equal to X?\"\n",
    "\n",
    "OR\n",
    "\n",
    "Bayesian: \"given the data, for the parameter of interest, what is the probability distribution over the possible values?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myCsIcO6n9hP"
   },
   "source": [
    "# Example 1: Coin toss problem\n",
    "\n",
    "I tossed my coin $ n $ times, and it came up as heads $ h $ times. Is it biased?\n",
    "\n",
    "In our example, assume that the data is $n = 30$, and $h = 12$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJVrkidBn9hP"
   },
   "source": [
    "## Questions to ask\n",
    "1. Bayesian: \"I want to know the distribution of $ p $, the probability of tossing heads. Given $ n $ tosses and $ h $ observed heads.\"\n",
    "\n",
    "Note that this question can not be asked in a frequentist framework. As a frequentist, $p$ is a fixed number, and the question would be \"What is the $p$ that is most likely to have generated the sample?\"\n",
    "\n",
    "\n",
    "2. Bayesian: \"What is the probaility that the coin is unbiased for practical purposes, i.e.,\n",
    " $ p $ in the interval $[0.48, 0.52]$?\"\n",
    "\n",
    "Note that this question can not be asked in a frequentist framework. A frequentist can only ask: \"assuming the null hypothesis $p = 0.5$ is true, how likely do I observe such a sample (p-value)?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwL18URIn9hP"
   },
   "source": [
    "## Prior\n",
    "\n",
    "- prior belief about parameter: $ p \\sim Uniform(0, 1) $\n",
    "- likelihood function: $ data \\sim Bernoulli(p) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HukHGoozn9hP"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T21:22:34.077586Z",
     "start_time": "2017-08-23T21:22:34.061409Z"
    },
    "id": "TCz9dXy3n9hP"
   },
   "outputs": [],
   "source": [
    "tosses = [1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0] #12 heads out of 30 tosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T21:22:34.103165Z",
     "start_time": "2017-08-23T21:22:34.079244Z"
    },
    "id": "0jvOjT59n9hP"
   },
   "outputs": [],
   "source": [
    "def plot_coins():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.bar(list(Counter(tosses).keys()), list(Counter(tosses).values()))\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['tails', 'heads'])\n",
    "    ax.set_ylim(0, 20)\n",
    "    ax.set_yticks(np.arange(0, 21, 5))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T21:22:34.267422Z",
     "start_time": "2017-08-23T21:22:34.104458Z"
    },
    "id": "Kh4qCkUIn9hP",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot_coins()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcCJKICjn9hP"
   },
   "source": [
    "**What is the MLE for $p$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKUuse22n9hP"
   },
   "source": [
    "## Model (how we think the data is generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T21:22:35.295159Z",
     "start_time": "2017-08-23T21:22:34.268480Z"
    },
    "id": "hZmxQR1wn9hP"
   },
   "outputs": [],
   "source": [
    "# Context manager syntax. `coin_model` is **just** \n",
    "# a placeholder\n",
    "with pm.Model() as coin_model: \n",
    "    # Distributions are PyMC3 objects.\n",
    "    # Specify prior using Uniform object.\n",
    "    p_prior = pm.Uniform('p', 0, 1)  \n",
    "    # Specify likelihood using Bernoulli object.\n",
    "    like = pm.Bernoulli('toss', p=p_prior, \n",
    "                        observed=tosses)  \n",
    "                        # \"observed=data\" is key\n",
    "                        # for likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T21:22:35.295159Z",
     "start_time": "2017-08-23T21:22:34.268480Z"
    },
    "id": "UsNskkuDn9hP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# do not worry about it in Colab\n",
    "pm.model_to_graphviz(coin_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWrXn6Y2n9hP"
   },
   "source": [
    "The above graph uses the [Plate Notation](https://en.wikipedia.org/wiki/Plate_notation) to represent a Bayesian graphical model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39uIxun_n9hP"
   },
   "source": [
    "Our prior is not really informative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNlD9eoKn9hP"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm, uniform\n",
    "x= np.arange(-1,2,0.01)\n",
    "plt.plot(x, uniform.pdf(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUMhrwNgn9hP"
   },
   "source": [
    "## MCMC Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T21:22:36.240221Z",
     "start_time": "2017-08-23T21:22:35.296349Z"
    },
    "id": "LlKFjnjzn9hP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with coin_model:\n",
    "    step = pm.Metropolis()\n",
    "    # sample from the posterior distribution\n",
    "    coin_trace = pm.sample(5000, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FawKsQnZn9hP"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T21:22:36.532476Z",
     "start_time": "2017-08-23T21:22:36.241308Z"
    },
    "id": "NUA27UVen9hP"
   },
   "outputs": [],
   "source": [
    "pm.traceplot(coin_trace, combined=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEwEZkm4n9hP"
   },
   "outputs": [],
   "source": [
    "coin_trace.get_values('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb_1krFKn9hP"
   },
   "source": [
    "The 95% **[Credible Interval](https://en.wikipedia.org/wiki/Credible_interval)** (not confidence interval!!) is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "29mH2FSgn9hP"
   },
   "outputs": [],
   "source": [
    "np.percentile(coin_trace.get_values('p'), [2.5, 97.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRcIAtS0n9hP"
   },
   "source": [
    "**Bayesian alternative to Hypothesis Testing:**  \n",
    "H0: The coin is balanced (p = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T21:22:36.847402Z",
     "start_time": "2017-08-23T21:22:36.533773Z"
    },
    "id": "ZlRs0l-In9hP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pm.plot_posterior(coin_trace,\n",
    "                  rope=[0.47, 0.53], point_estimate='mean', \n",
    "                  ref_val=0.5, hdi_prob=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4VFUOPrn9hP"
   },
   "source": [
    "- We can compare the 95% highest posterior density (HPD) (or credible interval) with region of practical equivalence (ROPE) as an equivalence to hypothesis testing in frequentist inference.  (See [this article](http://doingbayesiandataanalysis.blogspot.com/2013/08/how-much-of-bayesian-posterior.html) )\n",
    "- In our example, <font style=\"color:black; font-weight:bold\">95% highest posterior density (HPD)</font> encompasses the <font style=\"color:red; font-weight:bold\">region of practical equivalence (ROPE)</font>. \n",
    "- Cannot decide for certain if the coin is fair, need to get more data or change our prior!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9MwMwqGn9hP"
   },
   "source": [
    "## What if the prior is different?\n",
    "Say the treasury of the United States handed you a newly minted coin, and your prior belief is that the coin is more likely to be balanced. Our prior is very informative.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCQt9-5on9hP"
   },
   "outputs": [],
   "source": [
    "x= np.arange(0,1,0.01)\n",
    "plt.plot(x, norm.pdf(x, 0.5, 0.001))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qZ766ySn9hP"
   },
   "outputs": [],
   "source": [
    "with pm.Model() as coin_model: \n",
    "    # a very strong prior\n",
    "    p_prior = pm.Normal('p', 0.5, 0.01)  \n",
    "    like = pm.Bernoulli('toss', p=p_prior, \n",
    "                        observed=tosses)  \n",
    "            \n",
    "with coin_model:\n",
    "    step = pm.Metropolis()\n",
    "    coin_trace = pm.sample(5000, step=step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7hKjl0Zn9hP",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "            \n",
    "pm.plot_posterior(coin_trace[100:], color='#87ceeb', \n",
    "                  rope=[0.47, 0.53], point_estimate='mean', \n",
    "                  ref_val=0.5, hdi_prob=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaHTk8RBn9hP"
   },
   "source": [
    "## Bimodal prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xP89oi-xn9hP"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "x= np.arange(0,1,0.01)\n",
    "plt.plot(x, beta.pdf(x, 0.3, 0.6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HmqdtLvn9hP"
   },
   "outputs": [],
   "source": [
    "with pm.Model() as coin_model: \n",
    "    # a bimodal\n",
    "    p_prior = pm.Beta('p', 0.5, 0.5)  \n",
    "    like = pm.Bernoulli('toss', p=p_prior, \n",
    "                        observed=tosses)  \n",
    "            \n",
    "with coin_model:\n",
    "    step = pm.Metropolis()\n",
    "    coin_trace = pm.sample(5000, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUFH7ygQn9hP"
   },
   "outputs": [],
   "source": [
    "pm.plot_posterior(coin_trace[100:], color='#87ceeb', \n",
    "                  point_estimate='mean', \n",
    "                  ref_val=0.5, hdi_prob=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_3jAC-yn9hP"
   },
   "source": [
    "##  Summary\n",
    "\n",
    "1. parameterize your problem using statistical distributions\n",
    "1. justify your model structure\n",
    "1. write model in PyMC3, run inference. \n",
    "1. interpret based on posterior distributions\n",
    "1. (optional) with new information, modify model structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfR78-R3n9hP"
   },
   "source": [
    "# Example 2: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwMKk1yln9hP"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "boston=datasets.load_boston()\n",
    "boston_data = pd.DataFrame(boston.data)\n",
    "boston_data.columns = boston['feature_names']\n",
    "boston_data['MEDV'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oe-Y2b-4n9hP"
   },
   "outputs": [],
   "source": [
    "boston_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZILirVean9hP"
   },
   "source": [
    "## Bayesian Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASOmRMqFn9hP"
   },
   "source": [
    "By Default, the prior is  $p(θ) = N(0,10^{12}I)$. This is a very vague prior that will let the data speak for themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s160QDSHn9hP"
   },
   "outputs": [],
   "source": [
    "with pm.Model() as regression_model:\n",
    "    pm.glm.GLM.from_formula('MEDV ~ CRIM+ZN+INDUS+CHAS+NOX+RM+AGE+DIS+RAD+TAX+PTRATIO+B+LSTAT', \n",
    "                            boston_data, family=pm.glm.families.Normal())\n",
    "    normal_trace = pm.sample(3000, chains = 2, cores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyszgcUFn9hP"
   },
   "outputs": [],
   "source": [
    "# do not worry about it in Colab\n",
    "pm.model_to_graphviz(regression_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s13UKh9Cn9hP"
   },
   "outputs": [],
   "source": [
    "pm.plot_posterior(normal_trace, hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZjsZWyRn9hP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pm.summary(normal_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZb6hjJ7n9hP"
   },
   "source": [
    "## Compare with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ci151wmn9hP"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "y = boston_data[\"MEDV\"]\n",
    "X = boston_data.drop([\"MEDV\"], axis=1)\n",
    "model_sk = LinearRegression()\n",
    "model_sk.fit(X, y)\n",
    "pd.DataFrame(model_sk.coef_, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvvmOWyUn9hP"
   },
   "source": [
    "## Bayesian Ridge and Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb3PWrH9n9hP"
   },
   "source": [
    "The point estimates (*) of the above Bayesian regression with a more informative Gaussian prior is equivalent to a Ridge regression (L2 regularization). If we use a Laplace prior, they are equivalent to a Lasso regression (L1 regularization). \n",
    "\n",
    "(*) To be exact, the point estimate from the Bayesian regression is the maximum a posteriori (MAP) estimate, which is the mode of the posterior (highest point in the density function), not the mean. \n",
    "\n",
    "See reading *Prior and Regularization* for a proof. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f05epZZOn9hQ"
   },
   "source": [
    "### Bayesian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HeFMWdiHn9hQ"
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model_ridge:\n",
    "    # Define priors for intercept and regression coefficients.\n",
    "    priors = {'Intercept': pm.Normal.dist(mu=0, sigma=5000),\n",
    "              'Regressor': pm.Normal.dist(mu=0, sigma=1)\n",
    "    }\n",
    "    pm.glm.GLM.from_formula('MEDV ~ CRIM+ZN+INDUS+CHAS+NOX+RM+AGE+DIS+RAD+TAX+PTRATIO+B+LSTAT', \n",
    "                            boston_data, family=pm.glm.families.Normal(), priors=priors)\n",
    "    map_estimates = pm.find_MAP()\n",
    "    # No need the full posterior distribution\n",
    "#     normal_trace = pm.sample(500, chains = 2, cores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36G_2Ajtn9hQ"
   },
   "outputs": [],
   "source": [
    "map_estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tdDziq2n9hQ"
   },
   "source": [
    "Equivalent Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-WzRLLwZn9hQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model_l2 = Ridge(alpha=22.85) # Read the reading and find out why we use 22.85 \n",
    "model_l2.fit(X, y)\n",
    "pd.DataFrame(model_l2.coef_, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfBq9gqyn9hQ"
   },
   "source": [
    "### Bayesian Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wqybquvan9hQ"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import laplace\n",
    "x= np.arange(-2,2,0.01)\n",
    "plt.plot(x, laplace.pdf(x, 0, 0.2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vavaBsUfn9hQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model_lasso:\n",
    "    # Define priors for intercept and regression coefficients.\n",
    "    priors = {'Intercept': pm.Normal.dist(mu=0, sigma=5000),\n",
    "              'Regressor': pm.Laplace.dist(mu=0, b=0.01)\n",
    "    }\n",
    "    pm.glm.GLM.from_formula('MEDV ~ CRIM+ZN+INDUS+CHAS+NOX+RM+AGE+DIS+RAD+TAX+PTRATIO+B+LSTAT', \n",
    "                            boston_data, family=pm.glm.families.Normal(), priors=priors)\n",
    "    map_estimates = pm.find_MAP()\n",
    "    # No need the full posterior distribution\n",
    "#     normal_trace = pm.sample(500, chains = 2, cores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBxzOsRCn9hQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k, v in map_estimates.items():\n",
    "    print(\"{}: {}\".format(k, np.round(v,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSSquglXn9hQ"
   },
   "source": [
    "# Example 3: Hierarchical Linear Regression (Mixed Effects Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJKNYMiRn9hQ"
   },
   "source": [
    "Gelman et al.’s (2007) radon dataset is a classic for hierarchical modeling. In this dataset the amount of the radioactive gas radon has been measured among different households in all counties of several states. Radon gas is known to be the highest cause of lung cancer in non-smokers. It is believed to be more strongly present in households containing a basement and to differ in amount present among types of soil. Here we’ll investigate this differences and try to make predictions of radonlevels (y) in different counties based on the county itself and the presence of a basement (x). In this example we’ll look at Minnesota, a state that contains 85 counties in which different measurements are taken, ranging from 2 to 116 measurements per county.\n",
    "\n",
    "This is similar to the random effect model in experimental design.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CSxDFcQn9hQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import theano\n",
    "\n",
    "data = pd.read_csv(pm.get_data('radon.csv'))\n",
    "data['log_radon'] = data['log_radon'].astype(theano.config.floatX)\n",
    "county_names = data.county.unique()\n",
    "county_idx = data.county_code.values\n",
    "\n",
    "n_counties = len(data.county.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDAq377_n9hQ"
   },
   "outputs": [],
   "source": [
    "data[['log_radon', 'floor', 'county']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Jl6vVR-n9hQ"
   },
   "outputs": [],
   "source": [
    "with pm.Model() as hierarchical_model:\n",
    "    # Hyperpriors for group nodes\n",
    "    mu_a = pm.Normal('mu_a', mu=0., sigma=100)\n",
    "    sigma_a = pm.HalfNormal('sigma_a', 5.)\n",
    "    mu_b = pm.Normal('mu_b', mu=0., sigma=100)\n",
    "    sigma_b = pm.HalfNormal('sigma_b', 5.)\n",
    "\n",
    "    # Intercept for each county, distributed around group mean mu_a.\n",
    "    # Here we plug in a common group distribution for all a and b (which are\n",
    "    # vectors of length n_counties).\n",
    "    a = pm.Normal('a', mu=mu_a, sigma=sigma_a, shape=n_counties)\n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    b = pm.Normal('b', mu=mu_b, sigma=sigma_b, shape=n_counties)\n",
    "\n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy('eps', 5.)\n",
    "\n",
    "    radon_est = a[county_idx] + b[county_idx]*data.floor.values\n",
    "\n",
    "    # Data likelihood\n",
    "    radon_like = pm.Normal('randon', mu=radon_est,\n",
    "                           sigma=eps, observed=data.log_radon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qmp_hn-qn9hQ"
   },
   "outputs": [],
   "source": [
    "# do not worry about it in Colab\n",
    "pm.model_to_graphviz(hierarchical_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1J0Cv06n9hQ"
   },
   "outputs": [],
   "source": [
    "with hierarchical_model:\n",
    "    hierarchical_trace = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jg5KyJrwn9hQ"
   },
   "outputs": [],
   "source": [
    "pm.traceplot(hierarchical_trace,\n",
    "             var_names=['mu_a', 'mu_b',\n",
    "                        'sigma_a', 'sigma_b',\n",
    "                        'eps']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OClsGf_pn9hQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pm.summary(hierarchical_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXjuCLjUn9hQ"
   },
   "source": [
    "See full example: https://docs.pymc.io/notebooks/GLM-hierarchical.html"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "N_3jAC-yn9hP"
   ],
   "name": "Bayesian_Inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "633px",
    "left": "0px",
    "right": "1258px",
    "top": "106px",
    "width": "260.4px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
